\documentclass[12pt, a4paper]{article}
\usepackage{sectsty}
\usepackage{amsmath}
\usepackage{enumitem}
\usepackage{nicefrac}
\sectionfont{\fontsize{12}{15}\selectfont}
\subsectionfont{\fontsize{10}{12}\selectfont}
\begin{document}
\title{"Planning and Heuristic Search" \\ Oral Pre-Exam Questions (WS 2018/19)}
\author{Disclaimer: the given answers are not official.}
\date{}
\maketitle
%\input{oral-questions-1}
\section{What are nodes and edges representing in an OR graph?}
Nodes represent states of a given problem (e.g. board configurations in the 8-puzzle). Edges represent operations (solution steps) that should simplify the problem.


\section{What is a solution path in an OR-graph?}
A path \textit{P} in a state-space graph \textit{G} from node \textit{n} to goal node $\gamma$ in \textit{G}, satisfying given solution constraint,  is called a \textit{solution path} for \textit{n}. 
\subsection*{What is a solution base?}
A path \textit{P} in \textit{G} from \textit{n} to some node \textit{n'} is called \textit{solution base} for \textit{n}.


\section{What are constraint satisfaction problems? What are optimization problems?}
Constraint satisfaction problems are problems where a solution has to fulfill certain constraints and shall be found with minimum search effort. Optimization problems have to find a solution that in addition to the satisfication of constraints also has to stand out amongst all other solutions with respect to a special property.


\section{What is an appropriate representation for infinite graphs?}
The implicit representation is appropriate for infinite graphs as it uses the computable methods \textit{successors()} or \textit{next\_successor()} to determine the direct successors of a node. Its counterpart the explicit representation can only handle finite graphs, as the graph G = (V, E) is explicitly definied.


\section{What is node expansion?}
Applying the function \textit{successors(n)} on a node \textit{n} and thereby creating all direct successors of this node in \textbf{one time step} is called \textit{node expansion}. (All algorithms we considered use node expansion as a basic step, except for the backtracking algorithm)
\subsection*{What is node generation?}
Applying the function \textit{next\_successor(n)} on a node \textit{n} and thereby creating an unseen direct successor (one at a time) is called \textit{node generation}.
\subsection*{What are the states of nodes?} \begin{itemize}
\item generated (living on OPEN)
\item explored (neither on OPEN or CLOSED in A*, since it means \textit{next\_succesor} was applied and there is still at least one unseen node which will be returned by the next call of \textit{next\_succesor}.)
\item expanded (living on CLOSED, except for reopening in A*)
\item unseen
\end{itemize}

\section{What are locally finite graphs? Why do we need them?}
Local finitness means that a node has only a finite number of direct succesors. We do need this property as otherwise we would be stuck in an infinite loop when calling the methods \textit{succesors} or \textit{next\_succesor}.

\section{What is a solution base (differences to solution paths)?}
See question 2. Informally it is the inital part of a possible solution path. Note that we don't necessarily need to find a goal node when following expanding a solution base.

\section{What is an efficient way of representing solution bases?}
Solution bases can be efficiently represented by a \textbf{backpointer path}. A \textit{backpointer} is a reference of a newly generated node, pointing to its parent.

\section{What is the tree Basic-OR-Search maintains?}
The tree maintained by Basic-OR-Search is called a \textit{traversal tree}. It is rooted in the start node \textit{s} and definied by node instances from \textit{G} and edges reverse to the backpointers. Path (\textit{n}, \ldots, \textit{s}), defined by the backpointers of the nodes, is reversed in the traversal tree as (\textit{s}, \ldots, \textit{n}) and is called a backpointer path.

\section{Why is the graph maintained by Basic-OR-Search a tree?}
(A traversal tree is not directly maintained by an algorithm, hence this question is not exact.) It is called traversal tree, because it is a tree-unfolding of a part of the explored subgraph of \textit{G}. Every instance of a node can only have one parent,as it only got one backpointer reference. We don't have cycles because a node in \textit{G} is represented by multiple instances in the traversal tree (if the node got multiple successors that is).

\section{Why is the traversal tree in Basic-OR-Search no subgraph of the OR-graph?}
In general traversal trees are no subgraphs of the  search space graph \textit{G} because traversal trees can contain multiple instances of nodes in \textit{G}.

\section{Are DFS and BFS variants of Basic-OR-Search? Why? / Why not?}
Yes. They use the same algorithm but their datastructure is implemented differently.
DFS uses a \textit{stack} as OPEN list, hence it uses the LIFO principle.
BFS on the other hand uses a \textit{queue} as OPEN list, hence it uses the FIFO principle.
Both algorithems can be converted into each other by only changing the implementation of the data structure of the OPEN list.
\ldots

\section{Comparison of DFS and BFS: Which algorithm is to be preferred when and why?}
DFS is preferred when:
\begin{itemize}
\item We are given plenty of equivalent solutions.
\item Dead ends can be recognized early, i.e. with considerable look-ahead.
\item There are no cyclic or infinite paths (or at least they can be avoided).
\end{itemize}
BFS is preferred when:
\begin{itemize}
\item We know a solution is not far away from the start node.
\item Solutions are rare and the tree is deep. (Because DFS will take way longer on those graphs.)
\end{itemize}
An issue with BFS is that it has to store the explored part of the graph completley in memory. So when a graph is very wide, BFS will need too much memory. However, with BFS we do terminate with a solution if one exists, whereas DFS could follow an endless fruitless path.

\section{Which nodes are stored on OPEN, which nodes on CLOSED?}
Nodes waiting to be expanded are storted on OPEN (this includes both \textit{generated} and \textit{explored} nodes which have not been expanded yet), whereas already expanded nodes are stored on CLOSED.

\section{Why is a function cleanup\_closed() needed in DFS?}
It is needed in order to not run out of memory because of nodes we actually don't need to reference anymore. The function \textit{cleanup\_closed} deletes nodes from the CLOSED list that are no longer required. It is based on the principles that nodes which fulfill the dead end requirement can be discarded without hesitation. If a node \textit{n} is discarded, check if  \textit{n} has any predecessors that are still part of a solution path. A node is part of a solution path if it has a successors on OPEN. Predecessors that are not part of a solution path can be discarded.

\section{What is iterative deepening?}
Increasing the depth-bound of DFS in an outerloop and run DFS with an increased depth-bound value \textit{k} over and over again.

\section{What information sources does the evaluation function f in BF use?}
\begin{enumerate}
\item evaluation of the information given by node \textit{n}
\item estimates of the complexity of the remaining problem at \textit{n} in relation to $\Gamma$
\item evaluations of the explored part \textit{G} of the search space graph
\item domain specific problem solving knowledge
\end{enumerate}

\section{What are the main differences between UCS and BF?}
Cost values in uniform-cost-search (UCS) are stored with the nodes. The OPEN list is organized as a heap, and nodes are explored with respect to the cheapest cost. UCS is also called "cheapest-first-search" and it basically is best-first-search (BFS) with some modifications.

\section{What is the difference in the evaluation functions of UCS and BF?}
Uniform-cost-search can only make use of the knowledge from the explored part of the search space graph, the evaluation function \textit{f} in BF can use domain specific knowlege.

\section{What is path discarding?}
For two paths leading to the same node, the one with the higher \textit{f}-value is discarded. (Path discarding is only used in BF* and its successors.)

\section{When using path discarding, is the traversal tree a subgraph of the search space graph?}
This questions aims at the removal of duplicates. With path discarding the traversal tree will represent cycle-free paths in $G$ starting in $s$. If $G$ is cyclic-free then it is a subgraph.

\section{Why can path discarding be problematic?}
Path discarding is irreversible. It entails the risk of not finding desired solutions. The risk can be eleminated by restricting the evaluation function to be orver-preserving. Path discarding is performed implicitly by maintaining at most one instantiation per node and, therefore, one backpointer per node.

\section{What does node reopening mean?}
Reopening means moving a node from CLOSED to OPEN because the node could be reached with a better \textit{f}-value than the first time it was explored. (Note: Reopening of nodes can be avoided by using a monotonically increasing function \textit{f}, $f(n) \leq f(n')$ for successors $n'$ of $n$.)

\section{What is $C_P(s), C^*(s), \hat{C}_P(s), \hat{C}(s)$ ?}
\subsection{$C_P(s)$}
$C_P$ is a cost function which assigns each solution path $P$ and node $n$ in $P$ a cost value $C_P(n)$. $C_P(s)$  specifies the cost of a solution path  \textit{P} for \textit{s}: 
\begin{align*}
f(\gamma) = C_P(s)
\end{align*}
with $P$ backpointer path of $\gamma$.

\subsection{$C^*(s)$}
$C^*(s) = C^*$ is the optimum solution cost for s. \\
In general: $C^*(n) = $ inf $\{C_P(n) \mid P $ is solution path for $n$ in $G\}$ 

\subsection{$\hat{C}_P(s)$}
$\hat{C}_P(s)$ is the estimated optimum solution cost for $s$ in $G$ based on a solution base $P$ with cost function $C_P(n)$.
$\hat{C}_P(s)$ is optimistic iff $\hat{C}_P(n) \leq  C^*_P(n)$.

\subsection{$\hat{C}(s)$}
$\hat{C}(s)$ is the estimated optimum solution cost for $s$ (no solution base provided. so it searche in all solution bases) \\
Estimated optimum solution cost for node $n$ in $G$: \\
$\hat{C}(n) = $ inf $\{\hat{C}_P(n) \mid P $ is solution base in $G\}$ \\
A solution base $P$ for $s$ with $\hat{C}_P(s) = \hat{C}(s)$ is called most promising solution base (for $s$).

\section{How do we define an evaluation function f by a cost function $\hat{C}$?}
\textbf{UNSURE!} \\
We define $f(n)$ as $\hat{C}_P(n)$ with $P$ backpointer path of $n$: $f(n)$ is a recursive evaluation function.

\section{How do we define recursive cost functions?}
A cost function $C_P$ for a solution path $P$ is called recursive if for each node $n$ in $P$ holds:
$C_P(n) =  
\begin{cases}
F[E(n)] \quad \quad \quad \quad \text{$n$ is leaf in $P$, hence $n$ is goal node.} \\
F[E(n, C_P(n')] \quad \text{$n$ is inner node in $P$ and $n'$ direct succ. of $n$.}
\end{cases}
$

\section{How can we define a function $\hat{C}_P(n)$ for estimated solution cost on basis of recursive cost functions?}
$\hat{C}_P(n) =  
\begin{cases}
c(n) \quad \quad \quad \quad \quad \text{$n$ is leaf in $P$ and $P$ is solution path.} \\
h(n) \quad \quad \quad \quad \quad \text{$n$ is leaf in $P$ but $P$ is no solution path ($n$ in OPEN).} \\
F[E(n), \hat{C}_P(n')] \quad \text{$n$ is inner node in $P$ and $n'$ direct successor of $n$ in $P$.}
\end{cases}
$
\\\\
$E(n)$ denotes local properties of $n$ and $F$ is the so called cost measure. 
$P$ denotes a solution base. The estimated value $h(n)$ is used as if it was correct in the computation of predecessors.

\section{Why can it be an advantage to use recursive cost functions?}
If we use a recursive cost function, we compute tail to front (Face-Value-Principle). This means going all the way down to $\gamma$ and then up again, combining the costs on the way. We have to comnsider the whole Path $P$ when using a recursive cost function. The advantage is then that we simply have to consider the costs of a single node and it's local properties instead of the whole path at once. It is basically a series of local computations.

\section{Can cost functions help to avoid problems in path discarding?}
Idea: Order preserving cost function can help to avoid following the wrong way and thus wrongfuly discarding a optimum paths.
Cost estimations for alternative solution bases must be independet of their shared continuation (S:III-80). $\hat{C}_P(n)$ must be \textit{order-preserving}.

\section{What is the evaluation function used in algorithm A*?}
In A* we use $f(n) = g(n) + h(n)$ as evaluation function.

\section{What is \textit{h} and what is \textit{g} in the evaluation function of algorithm A*?}
$g$ is the sum of edge cost values of the backpointer path from a given node (cost of backpointer path of a given node at some point in time.) \\\\
$h$ is the estimate of the optimum cost of a solution path from a given node. ($h(\gamma) = 0$.)

\section{What is path cost in algorithm A*?}
Sum of edge cost values along that path.

\section{Is the underlying path cost function $\hat{C}_P(s)$ in A* order preserving? Is this only true if we have
negative edge cost values?}
Idea: In A*: $f(n) = \hat{C}_{P_{s-n}}(s) = g_{P_{s-n}}(n) + h(n)$. Evaluation functions $f$ that rely on additive cost measures $F[e, c] = e + c$ are  oder-preserving. So $f(n)$ is order-preserving. It is not only true for negative edge cost values.


\section{Why do we need delayed termination in order to solve optimization problem? (Example?)}
Without delayed termination, BF would return as soon as it found a goal node $\gamma$. With delayed termination we terminate when we select the most promising soloution base from OPEN which happens to be a solution path. Assume we do not use delayed termination and we reached node $n$. The only two goal nodes, $\gamma_1, \gamma_2$ are descendents of $n$. $\gamma_1$ is first explored with a path cost of $100$. BF would immediatley terminate with $\gamma_1$ instead of exploring all possible children of $n$, which could lead to exploring $\gamma_2$ with a much smaller path cost. This is why we need delayed termination. In this case, we would terminate with the cheaper solution path if it happened to be the most promising solution base at this point in time.

\section{What is an optimistic evaluation function?}
An optimistic evaluation function underestimates cost. In particular the true cost of a solution path $P_{s-\gamma}$ extending a solution base $P_{s-n}$ exceeds its $f$-value: $C_{P_{s-\gamma}}(s) \geq f(\gamma)$.

\section{Why do we need optimistic evaluation functions in order to solve optimization problems? (Example?)}
Assume we have a graph with start node $s$ and it's two children $a$ and $b$. There is a goal node $\gamma_a$ and $\gamma_b$, reachable from $a$ and $b$ respectively. Also assume we use a non-optimistic evaluation function. If the $f$-value of $b$ would be $100$ but the actual cost for $P_{s-\gamma_b}$ would be $1$, we would still follow node $a$ if it's $f$-value was for example $5$. We would continue to follow $P_{s-\gamma_a}$ and reach a goal node. The actual cost would then be $5$ which is less than the $1$ we would've paid if we followed node $b$. But $b$ was overestimatic the actual cost, so we never considered the actual cheapest path in this graph.

\section{What is the motivation for specifying Prop(G) for search space graphs?}
Prop($G$):
\begin{enumerate}
\item Search space graph $G$ is an implicitly definied OR-graph.
\item $G$ has only a single start node $s$.
\item $G$ is locally finite.
\item For $G$ a set $\Gamma$ of goal nodes is given. 
\item Each path from $s$ to $\gamma \in \Gamma$ in $G$ is a solution path. In A*($\gamma$)$= true$, independent of the backpointer path of $\gamma$.
\item Each edge $(n, n')$ in $G$ has non-negative edge-cost $c(n, n')$. The pathcost is the sum of edge cost along that path.
\item $G$ has a positive lower bound $\delta$ of edge costs. $\delta$ is fixed $c(n, n') \geq \delta > 0$ for all $(n, n')$ in $G$.
\item For each node $n$ in $G$ there exists an heuristic estimate $h(n)$ for the cost of the cheapest path from $n$ to $\gamma$. $h(n) \geq 0$, since $h(\gamma) = 0)$ for $\gamma \in \Gamma$.
\end{enumerate}
Motivations for Prop($G$):
\begin{enumerate}
\item 
	\begin{enumerate}[label=(\alph*)] 
	\item \textbf{Implicitly}: Would not be possible to represent infinite graphs with explicit representation.
	\item \textbf{Directed OR-Graph}: We want to use A*, a BF algorithm for OR-graphs.
	\end{enumerate}
\item Simplification.
\item Node expansion. ForEach-Loop would not terminate if $successors$ would return infinite many nodes.
\item Maintenance of structure.
\item No additional constraints on solution paths.
\item 
	\begin{enumerate}[label=(\alph*)] 
	\item \textbf{non-negative cost}: Prune cyclic paths which would corrupt the backpointer structure.
	\item \textbf{sum of edge cost}: Requirement as A* uses additive cost measure. No other calculation is possible.
	\end{enumerate}
\item We get rid of infinite graphs which for example will half the edge cost values all the time, starting with $\nicefrac{1}{2}$ and thus creating an infinite path which we will follow if the other option has edge cost value greather than 1.
\item 
	\begin{enumerate}[label=(\alph*)] 
	\item \textbf{computable}: We want to implement it.
	\item \textbf{$h(n) \geq 0$}: as path cost must not be negative, the estimate should also be non-negative. (Worst case $h(n) = 0$: uninformed search.)
	\item \textbf{$h(\gamma) = 0$}: Simplicity.
	\end{enumerate}
\end{enumerate}

\section{What is the consequence of a positive lower bound of edge cost values for long paths?}
The cost of the path will eventually exceed any given bound if the path is only long enough due to the lower bound of edge cost values $\delta$ .

\section{Is existence of optimum cost solution paths guaranteed for search space graphs with Prop(G)?}
No. However, if there is a solution path, we can argue that there also is an optimum solution path in $G$. But we can not guarantee that there is any solution path in $G$ at all.

\section{What is completeness, what is admissibility for search algorithms?}
\textbf{Completeness}: The algorithm terminates with a solution, if one exists. \\
\textbf{Admissibility}: The algorithm terminates with an optium solution, if a solution exists.

\section{What are the main steps in proving completeness of A*?}
\begin{enumerate}
\item Assume that there is a solution path $P_{s-\gamma}$.
\item Due to the shallowest OPEN node, no termination.
\item Define $M = max(f(n))$ for $n \in P$.
\item $f(n) \leq M$ for all nodes on $P$.
\item $f(n') \geq M$ not selected before nodes on $P$.
\item Finite set of paths with cost $M$ starting in $s$.
\item $\gamma$ selected
\end{enumerate}

\section{Why can’t we prove termination of A* on infinite graphs?}
Because in the proof of termination of A* we use the fact that the number of cycle-free paths is finite in a finite graph, and therefore it can only exist a finite number of backpointer paths. We can not use this fact for infinite graphs. In other words: A* could follow an infinite path in an infinite graph and never terminate – hence we can not prove termination on infinite graphs. \\
\textbf{ATTENTION}: We can prove completness for infinite graphs, when we assume that there is a solution path. But to prove termination we are not allowed to assume this.

\section{What is a shallowest OPEN node?}
The shallowest OPEN node for a path $P$ is the first node we encounter on that path (starting from $s$) which is on OPEN.

\section{How do shallowest OPEN nodes help proving completeness?}
Due to the shallowest OPEN nodes, we can argue that A* will not terminate with "fail" since there always is an OPEN node which has to be selected for expansion.

\section{What is the additional property of shallowest OPEN nodes on optimum cost paths that is used for proving admissibility of A*?}
We use the lemma of \textit{C*-bounded OPEN nodes} which means that on an optimum cost path there has to be a shallowest OPEN node with $f(n) \leq C^*$. 

\section{What is the statement of the C* bounded OPEN node lemma?}
Let $G$ be a search space graph with $Prop(G)$ and let A* use an admissible heuristic function $h$. For each optimum path $P^{*}_{s-\gamma} \in \boldsymbol{P^*_{s-\gamma}}$ and at each point in time before A* terminates there is an OPEN node $n'$ on $P^{*}_{s-\gamma}$ with $f(n) \leq C^*$. 

\section{What is the definition of an admissible heuristic function?}
$h(n) \leq h^*(n)$ for all $n \in G$. (Admissible heuristic functions are thus optimistic estimates of the cheapest solution cost for a node in $G$.)

\section{What is the idea of the proof of the C* bounded OPEN node lemma?}
Assumption of opt. sol. path + combination of shallowest open node + optimally reachable node on optimum solution path + admissible heursitic function.

\section{What is the statement of the admissibility theorem for A*?}
A* is admissible when using an admissible heuristic function $h$ on search space graphs $G$ with $Prop(G)$.

\section{If we use a solution path $P_{s-\gamma}$ with cost $C \geq C^*$ instead of an optimum cost solution path, what is the statement we can prove instead of the $C^*$ bounded OPEN node lemma?}

\ldots We can not use the 3. step of the proof (optimally reachable) since we are not on an optimum cost solution path anymore \ldots

\section{What necessary and sufficient conditions for node expansion by A* did we consider?}
\begin{enumerate}
\item necessary: $f(n) \leq C^*$ 
\\ sufficient: $f(n) < C^*$.
\item necessary:  $\exists C^*$-bounded path $P_{s-n}$
\\ sufficient: $\exists$ strictly $C^*$-bounded path $P_{s-n}$.
\item necessary: $g^*(n) + h(n) \leq C^*$
\\ sufficient: $g^*(n) + h(n) < C^*$.
\end{enumerate}

\section{What are the nodes considered in necessary and sufficient conditions for node expansion by A*?}
\begin{enumerate}
\item nodes on OPEN
\item nodes on $C*$-bounded paths
\item \ldots
\end{enumerate}

\section{How can we increase efficiency by applying the necessary condition for node expansion of OPEN nodes by A*?}
\ldots

\section{How is monotonicity (consistency) for heuristic functions defined?}
Consistency: $h(n) \leq k(n, n') + h(n')$ \\
Monotonicity: $h(n) \leq c(n, n') + h(n')$

\section{How can monotonicity be proven from consistency? (Proof ideas.)}
Monotonicity follows from consistency since consistency states the triangle inequality for any pair of nodes $n, n'$ with $n'$ reachable from $n$ considering cost of the cheapest path. Monotoniciy considers special pairs of nodes $n' \in succ(n)$ and per definition holds: $k(n, n') \leq c(n, n')$.

\section{How can consistency be proven from monotonicity? (Proof.)}
Let $n_1$ be reachable from $n_0$ and let $P = (n_0, n_1, \ldots, n_l)$ be a cheapest path from $n_0$ to $n_l$. Using the monotonicity of $h$ it can be proven by induction over the path length that 
\begin{align*}
h(n_0) \leq \sum_{i=1}^l c(n_{i-1}, n_i) + h(n_l)
\end{align*}
Since a cheapest path $P$ was considered, we have $k(n_0, n_l) = \sum_{i=1}^{l} c(n_{i-1}, n_i)$ and hence proven consistency: $h(n) \leq k(n, n') + h(n')$.

\section{Why is it important to have both, monotonicity and consistency?}
Consistency is the more powerful statement, so for further proofs it makes sense to have consistency. However, to check if a heuristic function $h$ is consistent, is way harder than to check if it is monotone, since $k(n, n')$ had to be considered instead of $c(n, n')$. 

\section{Are monotone heuristic functions admissible? (Proof.)}
Yes. \\
Since $monotonicity \Leftrightarrow consistency$, it is enough to show that consistent heuristic functions $h$ are admissible. Proof (Sketch):
\begin{enumerate}
\item Let $h$ be consistent, i.e. $h(n) \leq k(n, n') + h(n')$ for all nodes $n, n'$ in $G$.
\item Consider an arbitrary node $n$.
\item If no goal node is reachable from $n$, then $h^*(n) = \infty$ and thus $h(n) \leq h^*(n)$.
\item If some goal node is reachable from $n$, then there is a goal node $\gamma$ reachable from $n$ with cheapest cost (Corollary: Solution Existence Entails Optimum).
\item Using $n' = \gamma$, we have $h(n) \leq k(n, \gamma) + h(\gamma)$, thus $h(n) \leq h^*(n) + 0$.
\item Since $n$ is arbitrary chosen, $h(n) \leq h^*(n)$ holds for all nodes. Hence $h$ is admissible.
\end{enumerate}

\section{Consider the 8-puzzle. Give an example of a monotone heuristic function.}
TODO: Check if this is true.
\begin{enumerate}
\item sum of misplaced tiles (Hamming Distance).
\item sum of manhatten distances of misplaced tiles (Manhatten Distance).
\end{enumerate}

\section{What is the advantage of using monotone heuristic functions in A*?}
When $h$ is monotone, we don't have to re-expand nodes which are already on closed. More formally: An A* algorithm that uses a monotone heuristic function $h$ will expand only nodes to which it has found cheapest paths: $g(n) = g^*(n), \quad \forall n \in$ CLOSED. 

\section{Give the outline of the proof of the No Reopening Theorem}
\begin{enumerate}
\item Assume that A* selects a node $n$ for expansion with $g(n) > g^*(n)$.
\item Let $P^*_{s-n}$ be a cheapest path from $s$ to $n$.
\item If $P^*_{s-n} \bigcap$ OPEN $ = \{n\}$, then all predecessors of $n$ on $P^*_{s-n}$ have been expanded and $g(n) = g^*(n)$, contradicting the assumption (Lemma: Shallowest OPEN node on optimum path).
\item $P^*_{s-n} \bigcup$ OPEN $ \neq \{n\}$, let $n'$ be the shallowest OPEN node on $P^*_{s-n}$.
\item Using $g(n') = g^*(n')$ and the monotonicity of $h$ we have $f(n') = g(n') + h(n') = g^*(n') + h(n') \leq g^*(n') + k(n', n) + h(n)$.
\item Since $n' \in P^*_{s-n}$, we have $g(n') + k(n', n) = g^*(n)$ and thus $f(n') \leq g^*(n) + h(n)$.
\item According to the assumption $g(n) > g^*(n)$ we have $f(n') < g(n) + h(n)$ and thus $f(n') < f(n)$.
\item A* selects $n'$ for expansion instead of $n$, contradicting the assumption. 
\end{enumerate}


\section{Should we always prefer monotone heuristic functions over admissible ones?}
Yes? Since monotonicity requires admissibility but admissibility does not guarantee monotonicity. With monotonicty we can reduce the complexity of A* because of the No Reopening Theorem.

\section{If we have two heuristic functions, the one more informed than the other on part A of the search
space graph and the other way round on part B, which heuristic function should we use in A* search?}

We should prefer the heuristic function that is more informed on part B. It is more important to have a good heuristic when near to a goal node than at the very beginning. Example: Distance Uni -> City: not important if 2km or 10km. But distance from here to blackboard is more important if it is 10m or 50cm. 

\section{Why is solving optimization problems with A* search an efficiency nightmare?}
The runtime of A* can be exponential, i.e. $2^n$. Also if several near-optimum solutions exist, then A* uniformly follows the different paths, spending a lot of time.

\section{What is the idea of the weighing approach?}
Evaluation function $f = g + h$ consists of a breadth-first-component (nodes close to $s$ are preferred) $g$, and a depth-first-component $h$. The general idea of the weighing approach is now to strengthen the depth-first-component to find "some" solution faster whilst guaranteeing that the cost of the foind solution will be near optimum. 

\section{Why do we expect that the search effort in WA* is less than in A*?}
WA* uses $f_{\epsilon} = g + (1 + \epsilon) \cdot h$.  It allows a solution to be error term $\epsilon$ worse than an optimal solution. Therefore we expect that the overall search effort for finding a non-optimal solution will be less than in A*.

\section{What properties should $h$ have in WA*, what properties should $(1 + \epsilon)h$ have?}
$h$ should be an admissible heuristic function. $\epsilon$ should be chosen in such a way that $(1 + \epsilon)h$ is not admissible. 

\section{What is the idea of the $A^*_{\epsilon}$ algorithm?}
Use two heuristic functions $h$ and $h_F$. $h$ is used to form $FOCAL = \{n \in OPEN \mid f(n) \leq (1 + \epsilon) \cdot \min_{n' \in OPEN}   f(n')\}$. $h_F(n)$ is used to estimate the computational effort for completing the search from $n$ and thus for the selection of nodes from FOCAL.

\section{What properties should $h$ have in $A^*_\epsilon$, what properties should $h_F$ have?}
$h$ should be admissible. No restrictions on $h_F$.

\section{Why do we expect that the search effort in $A^*_\epsilon$ less than in A*?}
Same reason as question 66, we allow a $\epsilon$-percentage deviation from optimum solution cost.

\section{What are the differences of WA* and $A^*_\epsilon$ to A* in pseudocode?}
WA*: We have to rewrite the selection from open in line 4. It should include the $(1 + \epsilon)h$ instead of only $g + h$. \\ \\
$A^*_\epsilon$ : Add a calculation of FOCAL and then select from FOCAL based on $h_F$.

\section{What cost $C$ of a solution path can be expected for $WA^*$ and $A^*_\epsilon$? (Preconditions.)}
$C \leq (1 + \epsilon) * C^*$ if $h$ is admissible, $\epsilon > 0$ and graph $G$ has $Prop(G)$ (keyword: $\epsilon$-admissibility).

\section{Which of the two algorithms $WA^*$ and $A^*_\epsilon$ is more powerful? (Using appropriate functions $h$ and $h_F$ .)}
$A^*_\epsilon$ is more powerful as it can simulate $WA^*$ but not the other way around.  

\section{What is the essential step in proving that $A^*_\epsilon$ can simulate $WA^*$?}
\ldots

\section{Is $WA^*$ complete? Is $A^*_\epsilon$ complete?}
Yes, WA*  is complete, since any results for $A^*$ that don't require an admissible heuristic function as a precondition are also valid for $WA^*$. Completness does not require any preconditions. \\ \\
Yes. Completness of $A^*_\epsilon$ can be proven analogously to the proof of completness of $A^*$ using $(1 + \epsilon) \cdot M$ as cost bound for paths. 

\section{How can we proof $\epsilon$-admissibility of $WA^*$ ?}
\begin{enumerate}
\item \textit{Theorem Completness of A*} implies completness of WA*, since WA* differs from A* only in the evaluation function used and since all restrictions for $h$ are also met by $(1 + \epsilon) h$.
\item Let WA* terminate with a goal node $\gamma$ and solution cost $C = f_{\epsilon}(\gamma)$.
\item Let $n'$ be the shallowest OPEN node on some optimal path at termination. Then we have $f_{\epsilon}(n') = g^*(n') + (1 + \epsilon) \cdot h(n') \leq (1 + \epsilon) \cdot (g^*(n') + h(n')) $.
\item Since $h$ is admissible, we have $f_{\epsilon}(n') \leq (1 + \epsilon) \cdot (g^*(n') + h^*(n'))$.
\item From $g^*(n') + h^*(n') = C^*$ (node on optimum path) follows that $f_\epsilon(n') \leq (1 + \epsilon) \cdot C^*$.
\item Since WA* selects nodes with smallest $f_{\epsilon}$-values, we have $C \leq f_\epsilon(n') \leq (1 + \epsilon) \cdot C^*$.
\end{enumerate}

\section{How can we proof $\epsilon$-admissibility of $A^*_\epsilon$}
\begin{enumerate}
\item Completness of $A^*_\epsilon$ can be proven analogously to the proof of completness of $A^*$ using $(1 + \epsilon) \cdot M$ as cost bound for paths. 
\item Let $A^*_\epsilon$ terminate with goal node $\gamma$ and solution cost $C = f(\gamma)$.
\item Let $n'$ be the shallowest OPEN node on an optimal path at termination. The we have $f(n') = g^*(n') + h(n').$ (\textit{Corallary "Shallowest OPEN node on optimum path")}.
\item Since $h$ is admissible, we have $f(n') \leq g^*(n') + h^*(n')$.
\item From $g^*(n') + h^*(n') = C^*$ (node on optimum path) follows that $f(n') \leq C^*$.
\item Let $n$ be the OPEN node with the smallest $f(n)$. By definition, we have $f(n) \leq f(n')$.
\item Since $\gamma$ was selected from FOCAL, we have $C \leq f(n) \cdot (1 + \epsilon)$.
\item Therefore $C \leq f(n') \cdot (1 + \epsilon)$.
\item Hence $C \leq C^* \cdot (1 + \epsilon)$. 
\end{enumerate}

\section{Does $A^*_\epsilon$ benefit from using monotone heuristic functions in the same way $A^*$ does?}
No. In $A^*_\epsilon$ monotone heuristic functions generally do not imply that nodes won't be re-expanded. \ldots

\section{What is restricted path discarding?}
Path discarding is only applied for nodes on OPEN, i.e. nodes that don't have been expanded yet. An $A^*_\epsilon$ algorithm using restricted path discarding is called $NRA^*_\epsilon$.
\ldots 

\section{What is the relation of cost $C$ of a solution path found by $NRA*_{\epsilon}$ to $C^*$?}
Let $N$ be the maximal length of an optimal solution path. If the heuristic function $h$ is monotone $NRA*_\epsilon$ terminates with solution cost \\
$C \leq (1 + \epsilon)^{N/2} \cdot C^*$.\\

\section*{{\huge Part Planning}}

\section{What is a STRIPS model and a STRIPS planning problem? Explain states, goals, CWA, DCA, UNA.}
STRIPS stands for \textit{Standford Research Inistitute Problem Solver}.
\subsection*{STRIPS model}
STRIPS model $ S = (C, P, O)$ is given by a finite set $P$ of predicate symbols with some arity, and a finite set $O$ of operator descriptions of the following form, and using only constants in $C$, predicates in $P$ and variables. \\ \\
operatorname($ x_1, \ldots,  x_n $) \\
precondition: finite list of literals describing preconditions. \\
effects: finite list of literals describing effects. 

\subsection*{STRIPS planning problem}
A STRIPS planning problem $(S, s_init, c_goal)$ is given by:
\begin{enumerate}
\item STRIPS model $S$
\item a start state $s_init$
\item a goal $c_goal$ definint conditions for goal states
\end{enumerate}


\subsection*{States}
A state is specified by a finite set (i.e. a conjunction) of variable-free atomic formulas (i.e. positive literals). A state in a STRIPS model is described by a finite set of variable-free positive literals assuming DCA, UNA, CWA.

\subsection*{Goals}
A STRIPS goal is described by a finite set of variable-free literals (can also be negative). \\
A goal is satisfied in a state if all non-negated literals of the goal description are contained in the state description and no negated literal of the goal description is contained in the state description. A state satisfying the goal is a \textit{goal state}.

\subsection*{CWA}
Closed World Assumption: All atomic forumlas of a state are assumed to be true, all other variable free atomic formulas are assumed to be false.

\subsection*{DCA}
Domain Closure Assumption: All objects in the domain are denoted by constants.

\subsection*{UNA}
Unique Name Assumption: Different constants denote different objects.

\section{How do we get from operators to actions?}
Actions are ground-instances of operators. That means we replace every variable in the arguments/preconditions/effects with variable-free (ground) literals, i.e. constants.

\section{What is a (solution-) plan?}
A plan is a sequence of actions $(a_1, \ldots, a_k)$. A solution plan is a plan which leads to a goalstate. To be more exact: A plan is a solution to a planning problem ($S, s_init, c_goal)$ iff there are states $s_1, \ldots, s_k$ such that
\begin{enumerate}
\item $a_i$ is applicable in $s_{i-1}$ and leads to state $s_i$ for $i = 1, \ldots, k$ and 
\item $s_k$ satisfies goal conditions $c_goal$.
\end{enumerate}

\subsection*{Applicable}
An action $a$ is applicable in state $s$ iff
\begin{enumerate}
\item all non-negated literals in the precondition of $a$ are contained in $s$ and
\item no negated literal in the precondition of $a$ is contained in $s$.
\end{enumerate}

\section{What is state-space-planning?}
\begin{itemize}

\item nodes = states / sets of states of the domain
\item edges = state transitions by actions
\item plan = path in the state space
\end{itemize}

\section{How does regression work?}
Regression Planning = Backwards Search in State Spaces. Instead of starting with the initial state, we could start with the goal description in order to add only "necessary" actions to a plan. Backwards Search does not work with states (sets of positive literals only) like forward search but with goals (set of positive and negative literals). Goals can be understood as partially definied states (CWA). The starting point of the Backwards Search ist the inverse of the state transition relation (weakest precondition). \ldots

\section{How can we construct heuristic functions for A* search in forward planning?}
Heuristics by simplified Models. 
\begin{itemize}
\item \textbf{Constraint Relaxation.} (Relaxation of a model is the removal of constraints that prohibit the use of operators. Cost of an optimum solution for a simplified problem can be used as an estimate for the optimum remaining cost.)
\item \textbf{Overconstraining.} (Additional constraints, e.g. fixing the initial part of solution paths, results in less complex models. Solution cost for such a model can be used as upper bounds for $C^*$ (pruning).)
\end{itemize}

\section{Explain the partial-order-planning approach.}
\ldots

\end{document}